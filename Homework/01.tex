\documentclass[11pt, oneside]{article}
\usepackage[letterpaper, margin=2cm]{geometry}
\usepackage{MATH565}
\usepackage{xspace}
\newcommand{\MATLAB}{\textsc{Matlab}\xspace}
\newcommand{\PYTHON}{\textsc{Python}\xspace}

\begin{document}
\noindent \textbf{\Large{Caleb Logemann \\
MATH 565 Continuous Optimization \\
Homework 1
}}

%\lstinputlisting[language=Python]{H01_23.m}
\begin{enumerate}
  \item % #1 Done
    Problem 1 \\
    Compute the gradient $\nabla f(x)$ and Hessian $\nabla^2 f(x)$ of the
    Rosenbrock function
    \[
      f(x) = 100\p{x_2 - x_1^2}^2 + (1 - x_1)^2
    \]

    The gradient of $f$ is defined as $\p{\pd{f}{x_1}, \pd{f}{x_2}}^T$.
    The first derivatives of $f$ are stated below.
    \begin{align*}
      \pd{f}{x_1} &= -400 x_1 \p{x_2 - x_1^2} - 2(1 - x_1) \\
      \pd{f}{x_2} &= 200\p{x_2 - x_1^2}
    \end{align*}
    So the gradient of $f$ is 
    \[
      \nabla f(x) =
      \begin{bmatrix}
        -400 x_1 \p{x_2 - x_1^2} - 2(1 - x_1) \\
        200\p{x_2 - x_1^2}
      \end{bmatrix}
    \]
    The Hessian of $f$ is the matrix
    \[
      \nabla^2 f(x) =
      \begin{bmatrix}
        \pd[2]{f}{x_1} & \mpd[2]{f}{\partial x_1 \partial x_2} \\
        \mpd[2]{f}{\partial x_2 \partial x_1} & \pd[2]{f}{x_2}
      \end{bmatrix}
    \]
    The second derivatives are shown below.
    \begin{align*}
      \pd[2]{f}{x_1} &= \pda{}{x_1}{\pd{f}{x_1}} \\
      &= -400\p{x_2 - x_1^2} + 800 x_1^2 + 2 \\
      &= -400\p{x_2 - 3x_1^2} + 2 \\
      \mpd[2]{f}{\partial x_1 \partial x_2} &= \pda{}{x_1}{\pd{f}{x_2}} \\
      &= -400 x_1 \\
      \pd[2]{f}{x_2} &= \pda{}{x_2}{\pd{f}{x_2}} \\
      &= 200
    \end{align*}
    Note that $\mpd[2]{f}{\partial x_2 \partial x_1} = \mpd[2]{f}{\partial x_1 \partial x_2}$
    as $f$ has continuous second derivatives.
    Thus the Hessian of $f$ is 
    \[
      \nabla^2 f(x) =
      \begin{bmatrix}
         -400\p{x_2 - 3x_1^2} + 2 & -400x_1 \\
        -400x_1 & 200
      \end{bmatrix}
    \]

  \item % #2 Done
    Problem 8 \\
    Suppose that $f$ is a convex function.
    Show that the set of global minimizers of $f$ is a convex set.

    \begin{proof}
      Let $f$ be a convex function.
      This implies that
      \[
        f(\lambda x + (1 - \lambda) y) \le \lambda f(x) + (1 - \lambda) f(y)
      \]
      for $\lambda \in \br{0, 1}$ and $x, y \in \RR^n$.
      Let $S = \set{x^* \in \RR^n : f(x^*) \le f(x) \forall x \in \RR^n}$ be
      the set of all global minimizers.
      Let $x_1^*, x_2^* \in S$ and let $\lambda \in \br{0, 1}$.
      Note that $f(x_1^*) = f(x_2^*)$ because in order for both of these to be
      global minimizers they must have the same functional value.
      Now consider the point $\lambda x_1^* + (1-\lambda)x_2^*$.
      Since $f$ is convex.
      \begin{align*}
        f(\lambda x_1^* + (1-\lambda)x_2^*) &\le \lambda f(x_1^*) + (1 - \lambda) f(x_2^*) \\
        &= \lambda f(x_1^*) + (1 - \lambda) f(x_1^*) \\
        &= f(x_1^*) \\
      \end{align*}
      This shows tha
      Also since $x_1^*$ is a global minimizer.
      \[
        f(\lambda x_1^* + (1-\lambda)x_2^*) \le f(x_1^*) \le f(x)
      \]
      for any $x \in \RR^n$.
      Thus $\lambda x_1^* + (1 - \lambda)x_2^* \in S$ and is a global minimizer.
      This shows that $S$ is convex.
    \end{proof}

  \item % #3
    Problem 9 \\
    Consider the function $f(x_1, x_2) = (x_1 + x_2^2)^2$.
    At the point $x^T = (1, 0)$ we consider the search direction $p^T = (-1, 1)$.
    Show that $p$ is a descent direction and find all minimizers of the problem
    (2.10).


  \item % #4
    Problem 13 \\
    Show that the sequence $x_k = 1/k$ is not Q-linearly convergent,
    though it does converge to zero.

  \item % #5
    Problem 14 \\
    Show that the sequence $x_k = 1 + (0.5)^{2^k}$ is Q-quadractically convergent
    to 1.

  \item % #6
    Consider the following fixed point iteration scheme:
    \[
      x_{k+1} = x_k - \frac{\br{g(x_k)}^2}{g(x_k + g(x_k)) - g(x_k)}
    \]
    Prove that if this method is converges to a root $x^*$ of $g(x)$ such that
    $g'(x^*)\neq 0$ and $g''(x^*) \neq 0$, then the rate of convergence is
    quadractic: $p = 2$.

    \begin{proof}
      
    \end{proof}

  \item % #7 Done
    Implement the method from problem 6 in \MATLAB (or \PYTHON if you prefer).
    Use it to solve problems 8 and 9.

    The following function implements the method from problem 6.
    \lstinputlisting[language=Python]{01_7.py}

  \item % #8
    The van der Waal equation
    \[
      \p{P + \frac{a}{V^2}}\p{V - b} = nRT
    \]
    generalizes the ideal gas law $PV = nRT$.
    In each equation, $P$ represents the pressure (atm), $V$ represents the volume
    (liters), $n$ is the number of moles of gas, and $T$ represents the temperature
    (K).
    $R$ is the universal gas constant and has the value
    \[
      R = 0.08205 \frac{\text{liters} \cdot \text{atm}}{\text{mole}\cdot \text{K}}
    \]
    Determine the volume of 1 mole of isobutane at a temperature of $T = 313 K$ and
    a pressure of $P = 2$ atm, given that, for isobutane,
    $a = 12.87 \text{atm} \cdot \text{liters}^2$ and $b = 0.1142$ liters.
    Compare this to the value predicted from the ideal gas law.
    You may use any one of your methods (make clear in your writeup which one
    you are using, what initial guesses or intervals you are using, etc...).

    The following script uses the method implemented in problem 7 to find the
    volume that satisfies the van der Waal equation.
    \lstinputlisting[language=Python]{01_8.py}

  \item % #9
    According to Archimedes’ law, when a solid of density σ is placed in a
    liquid of density $\rho$, it will sink to a depth $h$ that displaces an
    amount of liquid whose weight equals the weight of the solid.
    For a sphere of radius $r$, Archimedes law is
    \[
      \frac{1}{3} \pi \p{3rh^2 - h^3}\rho = \frac{4}{3}\pi r^3 \sigma
    \]
    Given $r = 5$, $\rho = 1$, and $\sigma = 0.6$, determine $h$.
    You may use any one of your methods (make clear in your writeup which one
    you are using, what initial guesses or intervals you are using, etc...).
    \lstinputlisting[language=Python]{01_9.py}

\end{enumerate}
\end{document}
